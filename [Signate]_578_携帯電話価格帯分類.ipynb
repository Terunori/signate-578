{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Terunori/signate-578/blob/main/%5BSignate%5D_578_%E6%90%BA%E5%B8%AF%E9%9B%BB%E8%A9%B1%E4%BE%A1%E6%A0%BC%E5%B8%AF%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3etX1LJrdpHT"
      },
      "source": [
        "【第21回_Beginner限定コンペ】携帯電話の機能データからの価格帯分類\n",
        "携帯電話の機能から販売価格を分類しよう！ \n",
        "\n",
        "https://signate.jp/competitions/578"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XUJgutmWYnm"
      },
      "source": [
        "links\n",
        "- [ニューラルネットワークの実装（基礎）](https://free.kikagaku.ai/tutorial/basic_of_deep_learning/learn/pytorch_basic)\n",
        "- [Pytorchによる多クラス分類の実装](https://venoda.hatenablog.com/entry/2020/10/03/075322#42-%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%81%AE%E5%AE%9A%E7%BE%A9)\n",
        "- [多クラス分類におけるF値](https://zenn.dev/hellorusk/articles/46734584386c49057e1b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Agj6MbFadm3R"
      },
      "outputs": [],
      "source": [
        "# GPUの状態確認\n",
        "! nvidia-smi\n",
        "\n",
        "# 起動時設定\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "tz_jst = timezone(timedelta(hours=9))\n",
        "connect_time = datetime.now(tz=tz_jst).strftime('%Y%m%d_%H%M')\n",
        "\n",
        "# Google Drive マウント\n",
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# signate connect\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/modules')\n",
        "import signateConnect\n",
        "\n",
        "! pip install signate\n",
        "\n",
        "signateConnect.connect()\n",
        "\n",
        "! signate files --competition-id=578"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvZIFauDehKO"
      },
      "outputs": [],
      "source": [
        "! signate download --competition-id=578"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FA3xaPj6e8uh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# idは学習データに含みたくないので除外\n",
        "df_train = pd.read_csv('train.csv').drop('id', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNIrvVEsfJVX"
      },
      "outputs": [],
      "source": [
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ3RF3bkjskn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 正規化\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_train.drop('price_range', axis=1))\n",
        "\n",
        "# 入力と出力に分解\n",
        "y = torch.LongTensor(df_train['price_range'].values)\n",
        "x = torch.Tensor(df_train.drop('price_range', axis=1).values)\n",
        "\n",
        "# デフォルトのデータセット定義を使用\n",
        "dataset = torch.utils.data.TensorDataset(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUv1i0r7x3sf"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BRa7UB36zzo"
      },
      "outputs": [],
      "source": [
        "# train_rate = .87\n",
        "train_rate = .65\n",
        "\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    dataset, \n",
        "    [int(len(dataset)*train_rate), int(len(dataset)*(1-train_rate))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqRSJSJ_7NDe"
      },
      "outputs": [],
      "source": [
        "# loader\n",
        "\n",
        "# 学習用Dataloader\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=batch_size, \n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# 評価用Dataloader\n",
        "valid_dataloader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, \n",
        "    batch_size=batch_size, \n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_tznzy47yY5"
      },
      "outputs": [],
      "source": [
        "# 動作確認\n",
        "batch_iterator = iter(train_dataloader)\n",
        "# 1番目の要素を取り出す\n",
        "inputs, labels = next(batch_iterator)\n",
        "print(inputs.size())\n",
        "print(labels.size())\n",
        "print(inputs[0])\n",
        "print(labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgjOGnmx8QfX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        inFeatures  = 20  # 入力層サイズ  : 入力特徴量の数\n",
        "        mid1Features = 48 # 中間層1サイズ : はじめに入力より大きくする\n",
        "        mid2Features = 32 # 中間層2サイズ : だんだん小さくする\n",
        "        mid3Features = 16 # 中間層3サイズ\n",
        "        outFeatures = 4   # 出力層サイズ  :  分類したいクラス数\n",
        "\n",
        "        self.fc1 = nn.Linear(inFeatures, mid1Features)\n",
        "        self.bn1 = nn.BatchNorm1d(mid1Features)\n",
        "        self.fc2 = nn.Linear(mid1Features, mid2Features)\n",
        "        self.bn2 = nn.BatchNorm1d(mid2Features)\n",
        "        self.fc3 = nn.Linear(mid2Features, mid3Features)\n",
        "        self.bn3 = nn.BatchNorm1d(mid3Features)\n",
        "        self.fc4 = nn.Linear(mid3Features, outFeatures)\n",
        "\n",
        "    def forward(self, x):     # 一次元なので全結合型DNN\n",
        "        x = self.fc1(x)       # 全結合層 KerasやNeural Network ConsoleではDense層, Affine層とも呼ばれる\n",
        "        x = self.bn1(x)       # Batch normalization層 勾配消失・爆発を防ぐ効果: → learning rateを大きくしても収束しやすくなる\n",
        "        x = F.relu(x)         # 活性化 ReLu使用\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, 0.2) # Dropout層\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8gQq03J8X8f"
      },
      "outputs": [],
      "source": [
        "# loss クロスエントロピー\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEuEGLQM8l6Q"
      },
      "outputs": [],
      "source": [
        "# 最適化手法\n",
        "import torch.optim as optim\n",
        "\n",
        "# Adam使用するとSGDより学習が速い(が、過学習もしやすい)\n",
        "learningRate = 1e-3\n",
        "optimizer = optim.Adam(net.parameters(), lr=learningRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqNZyW6t8qY6"
      },
      "outputs": [],
      "source": [
        "# エポック数\n",
        "num_epochs = 2500\n",
        "\n",
        "# 学習時と検証時で分けるためディクショナリを用意\n",
        "dataloaders_dict = {\n",
        "    'train': train_dataloader,\n",
        "    'val': valid_dataloader\n",
        "}\n",
        "\n",
        "# best\n",
        "best_f1 = 0\n",
        "best_net = 0\n",
        "\n",
        "# log\n",
        "epoch_log = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    if epoch % epoch_log == epoch_log-1:\n",
        "        print()\n",
        "        print(f'epoch: {epoch+1:4}')\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        \n",
        "        if phase == 'train':\n",
        "            # モデルを訓練モードに設定\n",
        "            net.train()\n",
        "        else:\n",
        "            # モデルを推論モードに設定\n",
        "            net.eval()\n",
        "        \n",
        "        # 損失和\n",
        "        epoch_loss = 0.0\n",
        "        # 正解数\n",
        "        epoch_corrects = 0\n",
        "        # f1macro\n",
        "        f1 = []\n",
        "        f1_macro = 0\n",
        "        \n",
        "        # DataLoaderからデータをバッチごとに取り出す\n",
        "        for inputs, labels in dataloaders_dict[phase]:\n",
        "\n",
        "            # GPU\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # optimizerの初期化\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # 学習時のみ勾配を計算させる設定にする\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = net(inputs)\n",
        "                \n",
        "                # 損失を計算\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                # ラベルを予測\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                # 訓練時はバックプロパゲーション\n",
        "                if phase == 'train':\n",
        "                    # 逆伝搬の計算\n",
        "                    loss.backward()\n",
        "                    # パラメータの更新\n",
        "                    optimizer.step()\n",
        "                \n",
        "                # イテレーション結果の計算\n",
        "                # lossの合計を更新\n",
        "                # PyTorchの仕様上各バッチ内での平均のlossが計算される。\n",
        "                # データ数を掛けることで平均から合計に変換をしている。\n",
        "                # 損失和は「全データの損失/データ数」で計算されるため、\n",
        "                # 平均のままだと損失和を求めることができないため。\n",
        "                epoch_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "                # 正解数の合計を更新\n",
        "                epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # F値計算 毎回やると重いので適当な頻度で実施\n",
        "                if epoch % 20 == 19:\n",
        "                    for i in range(4):\n",
        "                        tp, fp, fn, tn = 0,0,0,0\n",
        "                        for pred, fact in zip(preds, labels.data):\n",
        "                            if pred == fact == i:\n",
        "                              tp+=1\n",
        "                            elif i == pred:\n",
        "                              fp+=1\n",
        "                            elif i == fact:\n",
        "                              fn+=1\n",
        "                            else:\n",
        "                              tn+=1\n",
        "                        \n",
        "                        if tp == 0:\n",
        "                            f1.append(0)\n",
        "                        else:\n",
        "                            precision = tp/(tp+fp)\n",
        "                            recall = tp/(tp+fn)\n",
        "                            f1.append(2*precision*recall/(precision+recall))\n",
        "\n",
        "        # epochごとのlossと正解率を表示\n",
        "        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "        # 今回の評価指標であるf2macroを計算(f1が計算されたときのみ有効値でそれ以外だと0になる)\n",
        "        f1_macro = np.mean(f1)\n",
        "\n",
        "        if phase != 'train':\n",
        "            if f1_macro > best_f1: # 評価指標に対し最も良い状態の保存\n",
        "                best_net = net\n",
        "                best_f1 = f1_macro\n",
        "\n",
        "        if epoch % epoch_log == epoch_log-1:\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} F1: {:,.4f} Best: {:,.4f}'.format(phase, epoch_loss, epoch_acc, f1_macro, best_f1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzIilTS6Ak_b"
      },
      "outputs": [],
      "source": [
        "# 最終結果の保存\n",
        "# 今回はtestデータを推論した結果のcsvを送信するため直接必要なわけではない\n",
        "torch.save(net.state_dict(), './signate578_' +\n",
        "           str(epoch+1) + '.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhG4GCRxmkeO"
      },
      "outputs": [],
      "source": [
        "# 学習のvalidデータで確認\n",
        "f1 = []\n",
        "for inputs, labels in valid_dataloader:\n",
        "    # GPU\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    outputs = best_net(inputs)\n",
        "    \n",
        "    # ラベルを予測\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "        \n",
        "    # 正解数の合計を更新\n",
        "    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    # F値計算\n",
        "    for i in range(4):\n",
        "        tp, fp, fn, tn = 0,0,0,0\n",
        "        for pred, fact in zip(preds, labels.data):\n",
        "          if pred == fact == i:\n",
        "            tp+=1\n",
        "          elif i == pred:\n",
        "            fp+=1\n",
        "          elif i == fact:\n",
        "            fn+=1\n",
        "          else:\n",
        "            tn+=1\n",
        "        \n",
        "        if tp == 0:\n",
        "          f1.append(0)\n",
        "        else:\n",
        "          precision = tp/(tp+fp)\n",
        "          recall = tp/(tp+fn)\n",
        "          f1.append(2*precision*recall/(precision+recall))\n",
        "\n",
        "# epochごとのlossと正解率を表示\n",
        "epoch_acc = epoch_corrects.double() / len(valid_dataloader.dataset)\n",
        "f1_macro = np.mean(f1)\n",
        "\n",
        "print(epoch_acc, f1_macro)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQcL1TXQf1UI"
      },
      "outputs": [],
      "source": [
        "# 提出用CSVデータ作成\n",
        "import numpy as np\n",
        "\n",
        "# 推論\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_test_test = df_test.drop('id', axis=1)\n",
        "\n",
        "scaler.fit(df_test_test)\n",
        "test = torch.Tensor(df_test_test.values).to(device)\n",
        "\n",
        "out = best_net(test)\n",
        "_, preds = torch.max(out, 1)\n",
        "\n",
        "np_pred = preds.cpu().detach().numpy().astype(np.int64)\n",
        "\n",
        "df_test['result'] = pd.Series(np_pred)\n",
        "df_result = df_test.loc[:,['id','result']]\n",
        "\n",
        "df_result.to_csv('result.csv', sep=',', header=False, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j8O414u8UE0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[Signate] 578 携帯電話価格帯分類",
      "provenance": [],
      "authorship_tag": "ABX9TyPV6FPKc8ndc16RpegYQWr1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}